{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa34775f-bb61-40ce-9a96-17770e82a760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79.99960506699051, 20.00039493300949)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset (replace 'path_to_file.csv' with the actual file path)\n",
    "file_path = 'updated_food_inspection_cleaned.csv'\n",
    "food_inspection_data = pd.read_csv(file_path)\n",
    "\n",
    "# Define the features (X) and target (y)\n",
    "X = food_inspection_data.drop(columns=['Risk'])\n",
    "y = food_inspection_data['Risk']\n",
    "\n",
    "# Split the data into training and testing sets with an 80-20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate the percentage of training and testing data\n",
    "train_percent = (len(X_train) / len(food_inspection_data)) * 100\n",
    "test_percent = (len(X_test) / len(food_inspection_data)) * 100\n",
    "\n",
    "train_percent, test_percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "801a1b34-fe29-4e49-a837-88b6bb032e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81026, 16), (20257, 16), (81026,), (20257,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Redefine the target variable as 'Risk' and split the data accordingly\n",
    "\n",
    "# Define the features (X) and target (y)\n",
    "X = food_inspection_data.drop(columns=['Risk'])\n",
    "y = food_inspection_data['Risk']\n",
    "\n",
    "# Split the data into training and testing sets with an 80-20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the sizes of the split datasets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1a2f157-ea69-4571-8847-e1c84197dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.7502\n",
      "Precision: 0.6561\n",
      "Recall: 0.7502\n",
      "F1 Score: 0.6499\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1514    4    3]\n",
      " [ 367    4    3]\n",
      " [ 127    2    2]]\n",
      "--------------------------------------------------\n",
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.7394\n",
      "Precision: 0.7458\n",
      "Recall: 0.7394\n",
      "F1 Score: 0.7422\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1278  203   40]\n",
      " [ 178  169   27]\n",
      " [  37   43   51]]\n",
      "--------------------------------------------------\n",
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: Random Forest\n",
      "Accuracy: 0.8105\n",
      "Precision: 0.7924\n",
      "Recall: 0.8105\n",
      "F1 Score: 0.7781\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1487   22   12]\n",
      " [ 245  111   18]\n",
      " [  66   21   44]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes to reduce memory usage\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'  # Adjust if needed based on your encoded column names\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Please check the column names.\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Optionally downsample the dataset (use a fraction of the data)\n",
    "sample_fraction = 0.1  # Adjust the fraction as necessary to reduce the dataset size\n",
    "data_sampled = data.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "X_sampled = data_sampled.drop([target_column], axis=1)\n",
    "y_sampled = data_sampled[target_column]\n",
    "\n",
    "# Convert the features to a sparse matrix for memory efficiency\n",
    "X_sparse = sparse.csr_matrix(X_sampled)\n",
    "\n",
    "# Train-test split\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(X_sparse, y_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler(with_mean=False)  # with_mean=False for sparse matrices\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=500)),  # Increased max_iter\n",
    "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "    (\"Random Forest\", RandomForestClassifier())\n",
    "]\n",
    "\n",
    "# Function to evaluate models and print performance metrics\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Multi-class roc_auc_score\n",
    "    if y_proba is not None and len(set(y_test)) > 2:\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "        except ValueError as e:\n",
    "            auc_score = None\n",
    "            print(f\"Warning: {e}\")\n",
    "    elif y_proba is not None:\n",
    "        auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    else:\n",
    "        auc_score = None\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print out the metrics\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {auc_score:.4f}\" if auc_score else \"ROC AUC: Not applicable\")\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Loop through models and evaluate each\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436519c3-12ad-422b-af94-e942d18dd180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Classes: [0, 1, 2, 3]\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.8301\n",
      "Precision: 0.8256\n",
      "Recall: 0.8301\n",
      "F1 Score: 0.8026\n",
      "ROC AUC: 0.9045\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [   13 14923   152   101]\n",
      " [    5  2371  1174   201]\n",
      " [    3   470   122   719]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.84      0.98      0.91     15189\n",
      "           2       0.81      0.31      0.45      3751\n",
      "           3       0.70      0.55      0.62      1314\n",
      "\n",
      "    accuracy                           0.83     20257\n",
      "   macro avg       0.59      0.46      0.49     20257\n",
      "weighted avg       0.83      0.83      0.80     20257\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Classes: [0, 1, 2, 3]\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.7720\n",
      "Precision: 0.7400\n",
      "Recall: 0.7720\n",
      "F1 Score: 0.6976\n",
      "ROC AUC: 0.8029\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [    0 15052    46    91]\n",
      " [    0  3396   179   176]\n",
      " [    0   845    61   408]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.78      0.99      0.87     15189\n",
      "           2       0.63      0.05      0.09      3751\n",
      "           3       0.60      0.31      0.41      1314\n",
      "\n",
      "    accuracy                           0.77     20257\n",
      "   macro avg       0.50      0.34      0.34     20257\n",
      "weighted avg       0.74      0.77      0.70     20257\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Classes: [0, 1, 2, 3]\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.7746\n",
      "Precision: 0.7380\n",
      "Recall: 0.7746\n",
      "F1 Score: 0.7432\n",
      "ROC AUC: 0.7433\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [    0 14327   729   133]\n",
      " [    1  2675   901   174]\n",
      " [    0   604   246   464]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.81      0.94      0.87     15189\n",
      "           2       0.48      0.24      0.32      3751\n",
      "           3       0.60      0.35      0.45      1314\n",
      "\n",
      "    accuracy                           0.77     20257\n",
      "   macro avg       0.47      0.38      0.41     20257\n",
      "weighted avg       0.74      0.77      0.74     20257\n",
      "\n",
      "--------------------------------------------------\n",
      "Target Classes: [0, 1, 2, 3]\n",
      "Model: Naive Bayes\n",
      "Accuracy: 0.6402\n",
      "Precision: 0.6520\n",
      "Recall: 0.6402\n",
      "F1 Score: 0.6267\n",
      "ROC AUC: 0.6978\n",
      "Confusion Matrix:\n",
      " [[    3     0     0     0]\n",
      " [ 1885 12666   612    26]\n",
      " [  638  2808   285    20]\n",
      " [  395   834    71    14]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         3\n",
      "           1       0.78      0.83      0.80     15189\n",
      "           2       0.29      0.08      0.12      3751\n",
      "           3       0.23      0.01      0.02      1314\n",
      "\n",
      "    accuracy                           0.64     20257\n",
      "   macro avg       0.33      0.48      0.24     20257\n",
      "weighted avg       0.65      0.64      0.63     20257\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Classes: [0, 1, 2, 3]\n",
      "Model: AdaBoost\n",
      "Accuracy: 0.7399\n",
      "Precision: 0.6780\n",
      "Recall: 0.7399\n",
      "F1 Score: 0.6983\n",
      "ROC AUC: 0.6608\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [    3 14214   695   277]\n",
      " [    0  2947   570   234]\n",
      " [    0   584   526   204]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.80      0.94      0.86     15189\n",
      "           2       0.32      0.15      0.21      3751\n",
      "           3       0.29      0.16      0.20      1314\n",
      "\n",
      "    accuracy                           0.74     20257\n",
      "   macro avg       0.35      0.31      0.32     20257\n",
      "weighted avg       0.68      0.74      0.70     20257\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Classes: [0, 1, 2, 3]\n",
      "Model: Bagging Classifier\n",
      "Accuracy: 0.9098\n",
      "Precision: 0.9081\n",
      "Recall: 0.9098\n",
      "F1 Score: 0.9050\n",
      "ROC AUC: 0.8935\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [    0 14942   161    86]\n",
      " [    0  1085  2544   122]\n",
      " [    0   249   121   944]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.92      0.98      0.95     15189\n",
      "           2       0.90      0.68      0.77      3751\n",
      "           3       0.82      0.72      0.77      1314\n",
      "\n",
      "    accuracy                           0.91     20257\n",
      "   macro avg       0.66      0.60      0.62     20257\n",
      "weighted avg       0.91      0.91      0.90     20257\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Classes: [0, 1, 2, 3]\n",
      "Model: Extra Trees Classifier\n",
      "Accuracy: 0.8833\n",
      "Precision: 0.8854\n",
      "Recall: 0.8833\n",
      "F1 Score: 0.8715\n",
      "ROC AUC: 0.9745\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [    0 15046    73    70]\n",
      " [    0  1686  1969    96]\n",
      " [    0   327   108   879]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.88      0.99      0.93     15189\n",
      "           2       0.92      0.52      0.67      3751\n",
      "           3       0.84      0.67      0.75      1314\n",
      "\n",
      "    accuracy                           0.88     20257\n",
      "   macro avg       0.66      0.55      0.59     20257\n",
      "weighted avg       0.89      0.88      0.87     20257\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Classes: [0, 1, 2, 3]\n",
      "Model: XGBoost\n",
      "Accuracy: 0.8939\n",
      "Precision: 0.8924\n",
      "Recall: 0.8939\n",
      "F1 Score: 0.8861\n",
      "ROC AUC: 0.9611\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [    0 14947   161    81]\n",
      " [    0  1391  2219   141]\n",
      " [    0   256   116   942]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.90      0.98      0.94     15189\n",
      "           2       0.89      0.59      0.71      3751\n",
      "           3       0.81      0.72      0.76      1314\n",
      "\n",
      "    accuracy                           0.89     20257\n",
      "   macro avg       0.65      0.57      0.60     20257\n",
      "weighted avg       0.89      0.89      0.89     20257\n",
      "\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2792\n",
      "[LightGBM] [Info] Number of data points in the train set: 81026, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -8.469312\n",
      "[LightGBM] [Info] Start training from score -0.284864\n",
      "[LightGBM] [Info] Start training from score -1.703595\n",
      "[LightGBM] [Info] Start training from score -2.723485\n",
      "Target Classes: [0, 1, 2, 3]\n",
      "Model: LightGBM\n",
      "Accuracy: 0.8697\n",
      "Precision: 0.8682\n",
      "Recall: 0.8697\n",
      "F1 Score: 0.8571\n",
      "ROC AUC: 0.8135\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [   16 14917   162    94]\n",
      " [    1  1718  1840   192]\n",
      " [    4   322   127   861]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.88      0.98      0.93     15189\n",
      "           2       0.86      0.49      0.63      3751\n",
      "           3       0.75      0.66      0.70      1314\n",
      "\n",
      "    accuracy                           0.87     20257\n",
      "   macro avg       0.62      0.53      0.56     20257\n",
      "weighted avg       0.87      0.87      0.86     20257\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import (GradientBoostingClassifier, AdaBoostClassifier,\n",
    "                              BaggingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier  # Ensure DecisionTreeClassifier is imported\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.discriminant_analysis import (QuadraticDiscriminantAnalysis,\n",
    "                                            LinearDiscriminantAnalysis)\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd  # Ensure pandas is imported\n",
    "\n",
    "# Load your dataset\n",
    "# X, y = load_your_data()  # Replace this line with your dataset loading process\n",
    "\n",
    "# Example for generating random data (for illustration)\n",
    "# X = np.random.rand(100, 10)  # Example feature matrix with 100 samples and 10 features\n",
    "# y = np.random.randint(0, 2, 100)  # Example target vector (binary classification)\n",
    "\n",
    "# Split your data into training and testing sets\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes to reduce memory usage\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'  # Adjust if needed based on your encoded column names\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Please check the column names.\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Optionally downsample the dataset (use a fraction of the data)\n",
    "sample_fraction = 0.1  # Adjust the fraction as necessary to reduce the dataset size\n",
    "data_sampled = data.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "X_sampled = data_sampled.drop([target_column], axis=1)\n",
    "y_sampled = data_sampled[target_column]\n",
    "\n",
    "# Convert the features to a sparse matrix for memory efficiency\n",
    "# X_sparse = scipy.sparse.csr_matrix(X_sampled)  # If you're working with sparse matrices\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply scaling if needed (StandardScaler is commonly used)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier()),  # Gradient Boosting\n",
    "    (\"Support Vector Machine\", SVC(probability=True)),  # SVM with probability\n",
    "    (\"K-Nearest Neighbors\", KNeighborsClassifier()),  # K-Nearest Neighbors\n",
    "    (\"Naive Bayes\", GaussianNB()),  # Naive Bayes\n",
    "    (\"AdaBoost\", AdaBoostClassifier()),  # AdaBoost\n",
    "    (\"Bagging Classifier\", BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50)),  # Updated Bagging Classifier\n",
    "    (\"Extra Trees Classifier\", ExtraTreesClassifier()),  # Extra Trees Classifier\n",
    "    (\"XGBoost\", xgb.XGBClassifier()),  # XGBoost\n",
    "    (\"LightGBM\", lgb.LGBMClassifier()),  # LightGBM\n",
    "]\n",
    "\n",
    "# Function to evaluate models and print performance metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Function to evaluate models and print performance metrics\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Multi-class roc_auc_score\n",
    "    if y_proba is not None and len(set(y_test)) > 2:\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "        except ValueError as e:\n",
    "            auc_score = None\n",
    "            print(f\"Warning: {e}\")\n",
    "    elif y_proba is not None:\n",
    "        auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    else:\n",
    "        auc_score = None\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print out the target classes\n",
    "    print(f\"Target Classes: {sorted(set(y_train))}\")  # or use set(y_test) if you prefer\n",
    "    # Print out the metrics\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {auc_score:.4f}\" if auc_score else \"ROC AUC: Not applicable\")\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Loop through models and evaluate each\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf58ac5c-238b-42e8-baab-08371270494a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\saini\\anaconda3\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\saini\\anaconda3\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\saini\\anaconda3\\lib\\site-packages (from catboost) (3.8.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from catboost) (2.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\saini\\anaconda3\\lib\\site-packages (from catboost) (1.13.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\saini\\anaconda3\\lib\\site-packages (from catboost) (5.22.0)\n",
      "Requirement already satisfied: six in c:\\users\\saini\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\saini\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "24eb0032-7047-405a-87cf-a96d1481e059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CatBoost Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.97      0.91      1521\n",
      "           2       0.71      0.40      0.51       374\n",
      "           3       0.62      0.40      0.49       131\n",
      "\n",
      "    accuracy                           0.83      2026\n",
      "   macro avg       0.73      0.59      0.63      2026\n",
      "weighted avg       0.81      0.83      0.81      2026\n",
      "\n",
      "Error calculating ROC AUC: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "========================================\n",
      "Model: Nearest Centroid Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.83      0.50      0.62      1521\n",
      "           2       0.25      0.32      0.28       374\n",
      "           3       0.18      0.57      0.28       131\n",
      "\n",
      "    accuracy                           0.47      2026\n",
      "   macro avg       0.32      0.35      0.29      2026\n",
      "weighted avg       0.68      0.47      0.54      2026\n",
      "\n",
      "ROC AUC Score: N/A\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  an appropriate warning.\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  an appropriate warning.\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  an appropriate warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Histogram-Based Gradient Boosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.86      0.96      0.90      1521\n",
      "           2       0.70      0.41      0.52       374\n",
      "           3       0.54      0.44      0.48       131\n",
      "\n",
      "    accuracy                           0.82      2026\n",
      "   macro avg       0.52      0.45      0.48      2026\n",
      "weighted avg       0.81      0.82      0.81      2026\n",
      "\n",
      "Error calculating ROC AUC: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  an appropriate warning.\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  an appropriate warning.\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  an appropriate warning.\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the models you want to evaluate\n",
    "models = [\n",
    "    (\"CatBoost Classifier\", CatBoostClassifier(verbose=0)),  # CatBoost\n",
    "    (\"Nearest Centroid Classifier\", NearestCentroid()),  # Nearest Centroid\n",
    "    (\"Histogram-Based Gradient Boosting\", HistGradientBoostingClassifier())  # Histogram-based GB\n",
    "]\n",
    "\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # For multi-class, predict_proba will return probabilities for all classes\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Calculate ROC AUC for multi-class\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Assuming you have your data prepared and scaled\n",
    "# Example of scaling (make sure you do this before fitting the models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_scaled_dense)\n",
    "X_test_scaled = scaler.transform(X_test_scaled_dense)\n",
    "\n",
    "# Loop through models and evaluate each\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652fa1c1-1135-4662-b2be-d4ae484e19d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: Linear Discriminant Analysis\n",
      "Accuracy: 0.7384\n",
      "Precision: 0.6958\n",
      "Recall: 0.7384\n",
      "F1 Score: 0.6465\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      "[[1487    0   34]\n",
      " [ 362    4    8]\n",
      " [ 124    2    5]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes to reduce memory usage\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'  # Adjust if needed based on your encoded column names\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Please check the column names.\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Optionally downsample the dataset (use a fraction of the data)\n",
    "sample_fraction = 0.1  # Adjust the fraction as necessary to reduce the dataset size\n",
    "data_sampled = data.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "X_sampled = data_sampled.drop([target_column], axis=1)\n",
    "y_sampled = data_sampled[target_column]\n",
    "\n",
    "# Convert the features to a sparse matrix for memory efficiency\n",
    "X_sparse = sparse.csr_matrix(X_sampled)\n",
    "\n",
    "# Train-test split\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(X_sparse, y_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler(with_mean=False)  # with_mean=False for sparse matrices\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)\n",
    "\n",
    "# Convert scaled sparse matrices to dense format for LDA\n",
    "X_train_dense = X_train_scaled.toarray()\n",
    "X_test_dense = X_test_scaled.toarray()\n",
    "\n",
    "# Linear Discriminant Analysis Model\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Fit the model\n",
    "lda_model.fit(X_train_dense, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lda_model.predict(X_test_dense)\n",
    "y_proba = lda_model.predict_proba(X_test_dense)[:, 1] if hasattr(lda_model, \"predict_proba\") else None\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Multi-class ROC AUC score\n",
    "if y_proba is not None and len(set(y_test)) > 2:\n",
    "    try:\n",
    "        auc_score = roc_auc_score(y_test, lda_model.predict_proba(X_test_dense), multi_class='ovr')\n",
    "    except ValueError as e:\n",
    "        auc_score = None\n",
    "        print(f\"Warning: {e}\")\n",
    "elif y_proba is not None:\n",
    "    auc_score = roc_auc_score(y_test, lda_model.predict_proba(X_test_dense)[:, 1])\n",
    "else:\n",
    "    auc_score = None\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print out the metrics\n",
    "print(\"Model: Linear Discriminant Analysis\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {auc_score:.4f}\" if auc_score else \"ROC AUC: Not applicable\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "895d4eb0-a4c7-42bb-a463-7595deb04ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: Neural Network\n",
      "Accuracy: 0.7507\n",
      "Precision: 0.5636\n",
      "Recall: 0.7507\n",
      "F1 Score: 0.6439\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1521    0    0]\n",
      " [ 374    0    0]\n",
      " [ 131    0    0]]\n",
      "--------------------------------------------------\n",
      "Model: Perceptron\n",
      "Accuracy: 0.7507\n",
      "Precision: 0.5636\n",
      "Recall: 0.7507\n",
      "F1 Score: 0.6439\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1521    0    0]\n",
      " [ 374    0    0]\n",
      " [ 131    0    0]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes to reduce memory usage\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'  # Adjust if needed based on your encoded column names\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Please check the column names.\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Optionally downsample the dataset (use a fraction of the data)\n",
    "sample_fraction = 0.1  # Adjust the fraction as necessary to reduce the dataset size\n",
    "data_sampled = data.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "X_sampled = data_sampled.drop([target_column], axis=1)\n",
    "y_sampled = data_sampled[target_column]\n",
    "\n",
    "# Convert the features to a sparse matrix for memory efficiency\n",
    "X_sparse = sparse.csr_matrix(X_sampled)\n",
    "\n",
    "# Train-test split\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(X_sparse, y_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler(with_mean=False)  # with_mean=False for sparse matrices\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)\n",
    "\n",
    "# Convert the sparse matrices back to DataFrames for evaluation\n",
    "X_test_df = pd.DataFrame.sparse.from_spmatrix(X_test_scaled)\n",
    "\n",
    "# Function to evaluate models and print performance metrics\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Multi-class roc_auc_score\n",
    "    if y_proba is not None and len(set(y_test)) > 2:\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "        except ValueError as e:\n",
    "            auc_score = None\n",
    "            print(f\"Warning: {e}\")\n",
    "    elif y_proba is not None:\n",
    "        auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    else:\n",
    "        auc_score = None\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print out the metrics\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {auc_score:.4f}\" if auc_score else \"ROC AUC: Not applicable\")\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    (\"Neural Network\", MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=500)),  # Neural Network\n",
    "    (\"Perceptron\", Perceptron(max_iter=500))  # Perceptron\n",
    "]\n",
    "\n",
    "# Evaluate models\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d46acbf-486d-4454-9047-030d081c9fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ridge Regression\n",
      "Accuracy: 0.7498\n",
      "Precision: 0.5908\n",
      "Recall: 0.7498\n",
      "F1 Score: 0.6448\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1518    3    0]\n",
      " [ 373    1    0]\n",
      " [ 128    3    0]]\n",
      "--------------------------------------------------\n",
      "Model: Lasso Regression\n",
      "Accuracy: 0.7507\n",
      "Precision: 0.5636\n",
      "Recall: 0.7507\n",
      "F1 Score: 0.6439\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1521    0    0]\n",
      " [ 374    0    0]\n",
      " [ 131    0    0]]\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import RidgeClassifier, Lasso\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes to reduce memory usage\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'  # Adjust if needed based on your encoded column names\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Please check the column names.\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Optionally downsample the dataset (use a fraction of the data)\n",
    "sample_fraction = 0.1  # Adjust the fraction as necessary to reduce the dataset size\n",
    "data_sampled = data.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "X_sampled = data_sampled.drop([target_column], axis=1)\n",
    "y_sampled = data_sampled[target_column]\n",
    "\n",
    "# Convert the features to a sparse matrix for memory efficiency\n",
    "X_sparse = sparse.csr_matrix(X_sampled)\n",
    "\n",
    "# Train-test split\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(X_sparse, y_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler(with_mean=False)  # with_mean=False for sparse matrices\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    (\"Ridge Regression\", RidgeClassifier()),\n",
    "    (\"Lasso Regression\", Lasso(max_iter=500))  # Note: Lasso may not be suitable for classification directly\n",
    "]\n",
    "\n",
    "# Function to evaluate models and print performance metrics\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # For Lasso, if it's used in classification, we can round predictions to get binary output\n",
    "    if isinstance(model, Lasso):\n",
    "        y_pred = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Multi-class roc_auc_score\n",
    "    if y_proba is not None and len(set(y_test)) > 2:\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "        except ValueError as e:\n",
    "            auc_score = None\n",
    "            print(f\"Warning: {e}\")\n",
    "    elif y_proba is not None:\n",
    "        auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    else:\n",
    "        auc_score = None\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Print out the metrics\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {auc_score:.4f}\" if auc_score else \"ROC AUC: Not applicable\")\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Loop through models and evaluate each\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f38898-69bb-46f3-9125-35fddfd7bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06664a13-5223-4c1e-bcdb-ac8fb99f9831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.33      0.00         3\n",
      "           1       0.84      0.59      0.69     15189\n",
      "           2       0.26      0.28      0.27      3751\n",
      "           3       0.17      0.57      0.26      1314\n",
      "\n",
      "    accuracy                           0.53     20257\n",
      "   macro avg       0.32      0.44      0.31     20257\n",
      "weighted avg       0.69      0.53      0.59     20257\n",
      "\n",
      "ROC AUC Score: 0.7251219333132617\n",
      "Confusion Matrix:\n",
      " [[   1    1    1    0]\n",
      " [ 777 8982 2799 2631]\n",
      " [ 221 1439 1058 1033]\n",
      " [ 102  273  191  748]]\n",
      "========================================\n",
      "Model: Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.91      0.86      0.88     15189\n",
      "           2       0.54      0.61      0.57      3751\n",
      "           3       0.52      0.62      0.57      1314\n",
      "\n",
      "    accuracy                           0.80     20257\n",
      "   macro avg       0.49      0.52      0.51     20257\n",
      "weighted avg       0.81      0.80      0.80     20257\n",
      "\n",
      "ROC AUC Score: 0.7080921662085768\n",
      "Confusion Matrix:\n",
      " [[    0     2     1     0]\n",
      " [    6 13064  1702   417]\n",
      " [    0  1134  2299   318]\n",
      " [    1   215   286   812]]\n",
      "========================================\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.91      0.95      0.93     15189\n",
      "           2       0.76      0.59      0.66      3751\n",
      "           3       0.67      0.75      0.71      1314\n",
      "\n",
      "    accuracy                           0.87     20257\n",
      "   macro avg       0.58      0.57      0.57     20257\n",
      "weighted avg       0.86      0.87      0.86     20257\n",
      "\n",
      "ROC AUC Score: 0.9130046879668248\n",
      "Confusion Matrix:\n",
      " [[    0     2     0     1]\n",
      " [    5 14388   560   236]\n",
      " [    1  1292  2201   257]\n",
      " [    0   175   150   989]]\n",
      "========================================\n",
      "Model: Gradient Boosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.87      0.82      0.85     15189\n",
      "           2       0.42      0.37      0.39      3751\n",
      "           3       0.41      0.79      0.54      1314\n",
      "\n",
      "    accuracy                           0.74     20257\n",
      "   macro avg       0.43      0.49      0.44     20257\n",
      "weighted avg       0.76      0.74      0.74     20257\n",
      "\n",
      "ROC AUC Score: 0.8497354640501753\n",
      "Confusion Matrix:\n",
      " [[    0     1     1     1]\n",
      " [   86 12515  1786   802]\n",
      " [   29  1656  1379   687]\n",
      " [   11   170    99  1034]]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# First set of 5 models\n",
    "models_1 = [\n",
    "    (\"Logistic Regression\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', LogisticRegression(max_iter=3000, class_weight='balanced'))])),\n",
    "    \n",
    "    (\"Decision Tree\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', DecisionTreeClassifier(class_weight='balanced'))])),\n",
    "    \n",
    "    (\"Random Forest\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', RandomForestClassifier(random_state=42))])),\n",
    "    \n",
    "    (\"Gradient Boosting\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', GradientBoostingClassifier(random_state=42))])),\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "# Loop through models and evaluate\n",
    "for name, model in models_1:\n",
    "    evaluate_model(name, model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4ede873-7eb6-4359-9261-466d75af65b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      "Risk\n",
      "1    6102\n",
      "2    1476\n",
      "3     522\n",
      "0       2\n",
      "Name: count, dtype: int64\n",
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: Linear Discriminant Analysis with SMOTE\n",
      "Accuracy: 0.5123\n",
      "Precision: 0.6827\n",
      "Recall: 0.5123\n",
      "F1 Score: 0.5700\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      "[[  0   0   0   0]\n",
      " [121 843 308 249]\n",
      " [ 20 143 119  92]\n",
      " [  4  32  19  76]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes to reduce memory usage\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'  # Adjust if needed based on your encoded column names\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Please check the column names.\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Optionally downsample the dataset (use a fraction of the data)\n",
    "sample_fraction = 0.1  # Adjust the fraction as necessary to reduce the dataset size\n",
    "data_sampled = data.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "X_sampled = data_sampled.drop([target_column], axis=1)\n",
    "y_sampled = data_sampled[target_column]\n",
    "\n",
    "# Convert the features to a sparse matrix for memory efficiency\n",
    "X_sparse = sparse.csr_matrix(X_sampled)\n",
    "\n",
    "# Train-test split\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(X_sparse, y_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the class distribution in the training set\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Apply SMOTE to balance the classes\n",
    "# Set k_neighbors=1 to avoid issues with few minority class samples\n",
    "smote = SMOTE(random_state=42, k_neighbors=1)  \n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_sparse.toarray(), y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test_sparse.toarray())\n",
    "\n",
    "# Linear Discriminant Analysis Model\n",
    "lda_model = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Fit the model\n",
    "lda_model.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = lda_model.predict(X_test_scaled)\n",
    "y_proba = lda_model.predict_proba(X_test_scaled)[:, 1] if hasattr(lda_model, \"predict_proba\") else None\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Multi-class ROC AUC score\n",
    "if y_proba is not None and len(set(y_test)) > 2:\n",
    "    try:\n",
    "        auc_score = roc_auc_score(y_test, lda_model.predict_proba(X_test_scaled), multi_class='ovr')\n",
    "    except ValueError as e:\n",
    "        auc_score = None\n",
    "        print(f\"Warning: {e}\")\n",
    "elif y_proba is not None:\n",
    "    auc_score = roc_auc_score(y_test, lda_model.predict_proba(X_test_scaled)[:, 1])\n",
    "else:\n",
    "    auc_score = None\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print out the metrics\n",
    "print(\"Model: Linear Discriminant Analysis with SMOTE\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {auc_score:.4f}\" if auc_score else \"ROC AUC: Not applicable\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b1c819-f239-41c5-b28e-47da88bd594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: K-Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.87      0.74      0.80     15189\n",
      "           2       0.34      0.46      0.39      3751\n",
      "           3       0.39      0.65      0.49      1314\n",
      "\n",
      "    accuracy                           0.68     20257\n",
      "   macro avg       0.40      0.46      0.42     20257\n",
      "weighted avg       0.74      0.68      0.70     20257\n",
      "\n",
      "ROC AUC Score: 0.7014533119797475\n",
      "Confusion Matrix:\n",
      " [[    0     1     2     0]\n",
      " [   18 11216  3092   863]\n",
      " [    5  1536  1732   478]\n",
      " [    3   205   255   851]]\n",
      "========================================\n",
      "Model: Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         3\n",
      "           1       0.87      0.28      0.42     15189\n",
      "           2       0.19      0.44      0.27      3751\n",
      "           3       0.15      0.53      0.23      1314\n",
      "\n",
      "    accuracy                           0.32     20257\n",
      "   macro avg       0.30      0.56      0.23     20257\n",
      "weighted avg       0.70      0.32      0.38     20257\n",
      "\n",
      "ROC AUC Score: 0.7018811824198783\n",
      "Confusion Matrix:\n",
      " [[   3    0    0    0]\n",
      " [1332 4194 6845 2818]\n",
      " [ 474  545 1656 1076]\n",
      " [ 306   87  231  690]]\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: AdaBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.82      0.71      0.76     15189\n",
      "           2       0.21      0.21      0.21      3751\n",
      "           3       0.26      0.64      0.37      1314\n",
      "\n",
      "    accuracy                           0.61     20257\n",
      "   macro avg       0.32      0.39      0.34     20257\n",
      "weighted avg       0.67      0.61      0.64     20257\n",
      "\n",
      "ROC AUC Score: 0.6606811080378101\n",
      "Confusion Matrix:\n",
      " [[    0     1     0     2]\n",
      " [   54 10812  2790  1533]\n",
      " [   14  2048   788   901]\n",
      " [   11   273   185   845]]\n",
      "========================================\n",
      "Model: Bagging Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.91      0.93      0.92     15189\n",
      "           2       0.72      0.61      0.66      3751\n",
      "           3       0.61      0.71      0.66      1314\n",
      "\n",
      "    accuracy                           0.86     20257\n",
      "   macro avg       0.56      0.56      0.56     20257\n",
      "weighted avg       0.86      0.86      0.86     20257\n",
      "\n",
      "ROC AUC Score: 0.8659973669425541\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [    5 14189   691   304]\n",
      " [    1  1182  2271   297]\n",
      " [    1   184   191   938]]\n",
      "========================================\n",
      "Model: Extra Trees Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.89      0.95      0.92     15189\n",
      "           2       0.72      0.51      0.59      3751\n",
      "           3       0.68      0.72      0.70      1314\n",
      "\n",
      "    accuracy                           0.85     20257\n",
      "   macro avg       0.57      0.54      0.55     20257\n",
      "weighted avg       0.84      0.85      0.84     20257\n",
      "\n",
      "ROC AUC Score: 0.9390365310714168\n",
      "Confusion Matrix:\n",
      " [[    0     2     1     0]\n",
      " [    5 14378   602   204]\n",
      " [    1  1607  1903   240]\n",
      " [    0   221   151   942]]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Second set of 5 models\n",
    "models_2 = [\n",
    "    (\"K-Nearest Neighbors\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', KNeighborsClassifier())])),\n",
    "    \n",
    "    (\"Naive Bayes\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', GaussianNB())])),\n",
    "    \n",
    "    (\"AdaBoost\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', AdaBoostClassifier())])),\n",
    "    \n",
    "    (\"Bagging Classifier\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', BaggingClassifier(n_estimators=50, random_state=42))])),\n",
    "    \n",
    "    (\"Extra Trees Classifier\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', ExtraTreesClassifier(random_state=42))]))\n",
    "]\n",
    "\n",
    "# Loop through models and evaluate\n",
    "for name, model in models_2:\n",
    "    evaluate_model(name, model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afa9e3c-55c9-4159-b5b6-f137766cc6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:947: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Quadratic Discriminant Analysis\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.80      0.79      0.80     15189\n",
      "           2       0.31      0.22      0.26      3751\n",
      "           3       0.24      0.47      0.32      1314\n",
      "\n",
      "    accuracy                           0.67     20257\n",
      "   macro avg       0.34      0.37      0.34     20257\n",
      "weighted avg       0.68      0.67      0.67     20257\n",
      "\n",
      "ROC AUC Score: 0.629111773826184\n",
      "Confusion Matrix:\n",
      " [[    0     2     0     1]\n",
      " [    1 12054  1719  1415]\n",
      " [    0  2375   831   545]\n",
      " [    1   571   129   613]]\n",
      "========================================\n",
      "Model: Histogram-Based Gradient Boosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.90      0.93      0.91     15189\n",
      "           2       0.72      0.49      0.59      3751\n",
      "           3       0.55      0.78      0.65      1314\n",
      "\n",
      "    accuracy                           0.84     20257\n",
      "   macro avg       0.54      0.55      0.54     20257\n",
      "weighted avg       0.84      0.84      0.83     20257\n",
      "\n",
      "ROC AUC Score: 0.8473610782478216\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [   16 14133   637   403]\n",
      " [    6  1455  1851   439]\n",
      " [    1   195    87  1031]]\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [18:47:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.90      0.95      0.92     15189\n",
      "           2       0.77      0.54      0.63      3751\n",
      "           3       0.61      0.79      0.69      1314\n",
      "\n",
      "    accuracy                           0.86     20257\n",
      "   macro avg       0.57      0.57      0.56     20257\n",
      "weighted avg       0.86      0.86      0.85     20257\n",
      "\n",
      "ROC AUC Score: 0.9335244816578858\n",
      "Confusion Matrix:\n",
      " [[    0     1     1     1]\n",
      " [   15 14358   520   296]\n",
      " [    4  1360  2026   361]\n",
      " [    1   191    87  1035]]\n",
      "========================================\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3067\n",
      "[LightGBM] [Info] Number of data points in the train set: 243764, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "Model: LightGBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.89      0.92      0.91     15189\n",
      "           2       0.69      0.47      0.56      3751\n",
      "           3       0.54      0.80      0.64      1314\n",
      "\n",
      "    accuracy                           0.83     20257\n",
      "   macro avg       0.53      0.55      0.53     20257\n",
      "weighted avg       0.83      0.83      0.83     20257\n",
      "\n",
      "ROC AUC Score: 0.918870443159423\n",
      "Confusion Matrix:\n",
      " [[    0     1     1     1]\n",
      " [   16 14036   722   415]\n",
      " [    2  1518  1754   477]\n",
      " [    1   188    77  1048]]\n",
      "========================================\n",
      "Model: CatBoost Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.90      0.94      0.92     15189\n",
      "           2       0.74      0.54      0.62      3751\n",
      "           3       0.60      0.77      0.68      1314\n",
      "\n",
      "    accuracy                           0.85     20257\n",
      "   macro avg       0.56      0.56      0.56     20257\n",
      "weighted avg       0.85      0.85      0.85     20257\n",
      "\n",
      "ROC AUC Score: 0.9356760093371789\n",
      "Confusion Matrix:\n",
      " [[    0     1     1     1]\n",
      " [   14 14291   590   294]\n",
      " [    3  1360  2013   375]\n",
      " [    1   196   102  1015]]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Model list with only the specified classifiers\n",
    "models = [\n",
    "    (\"Quadratic Discriminant Analysis\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', QuadraticDiscriminantAnalysis())])),\n",
    "    \n",
    "    (\"Histogram-Based Gradient Boosting\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', HistGradientBoostingClassifier(random_state=42))])),\n",
    "    \n",
    "    (\"XGBoost\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))])),\n",
    "    \n",
    "    (\"LightGBM\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', lgb.LGBMClassifier(random_state=42))])),\n",
    "    \n",
    "    (\"CatBoost Classifier\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', CatBoostClassifier(silent=True))]))\n",
    "]\n",
    "\n",
    "# Loop through models and evaluate\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6164758a-796d-4c4e-bd72-e8917499b019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Neural Network\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.85      0.78      0.81     15189\n",
      "           2       0.29      0.29      0.29      3751\n",
      "           3       0.37      0.74      0.49      1314\n",
      "\n",
      "    accuracy                           0.68     20257\n",
      "   macro avg       0.38      0.45      0.40     20257\n",
      "weighted avg       0.72      0.68      0.69     20257\n",
      "\n",
      "ROC AUC Score: 0.8094946690821875\n",
      "Confusion Matrix:\n",
      " [[    0     2     1     0]\n",
      " [   27 11797  2481   884]\n",
      " [    3  1906  1081   761]\n",
      " [    4   156   187   967]]\n",
      "========================================\n",
      "Model: Perceptron\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.33      0.00         3\n",
      "           1       0.80      0.46      0.58     15189\n",
      "           2       0.19      0.28      0.22      3751\n",
      "           3       0.13      0.52      0.21      1314\n",
      "\n",
      "    accuracy                           0.43     20257\n",
      "   macro avg       0.28      0.40      0.25     20257\n",
      "weighted avg       0.65      0.43      0.49     20257\n",
      "\n",
      "ROC AUC Score: N/A\n",
      "Confusion Matrix:\n",
      " [[   1    0    2    0]\n",
      " [ 684 6912 4281 3312]\n",
      " [ 193 1335 1033 1190]\n",
      " [  91  362  178  683]]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Model list including Neural Network and Perceptron\n",
    "models = [\n",
    "    (\"Neural Network\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=500))])),\n",
    "    \n",
    "    (\"Perceptron\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', Perceptron(max_iter=500))]))\n",
    "]\n",
    "\n",
    "# Loop through models and evaluate\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "046d6d02-487f-48e1-be19-0a5278a93896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Nearest Centroid Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         3\n",
      "           1       0.84      0.51      0.63     15189\n",
      "           2       0.24      0.30      0.27      3751\n",
      "           3       0.17      0.52      0.26      1314\n",
      "\n",
      "    accuracy                           0.47     20257\n",
      "   macro avg       0.31      0.58      0.29     20257\n",
      "weighted avg       0.69      0.47      0.54     20257\n",
      "\n",
      "ROC AUC Score: N/A\n",
      "Confusion Matrix:\n",
      " [[   3    0    0    0]\n",
      " [1856 7710 3331 2292]\n",
      " [ 492 1200 1110  949]\n",
      " [ 209  243  183  679]]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Nearest Centroid Classifier with scaling\n",
    "nearest_centroid_model = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('classifier', NearestCentroid())\n",
    "])\n",
    "\n",
    "# Evaluate Nearest Centroid Classifier\n",
    "evaluate_model(\"Nearest Centroid Classifier\", nearest_centroid_model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92023657-e631-4320-a9e0-d86920ab7c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=6.39633e-17): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Ridge Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         3\n",
      "           1       0.84      0.55      0.66     15189\n",
      "           2       0.26      0.19      0.22      3751\n",
      "           3       0.18      0.58      0.28      1314\n",
      "\n",
      "    accuracy                           0.49     20257\n",
      "   macro avg       0.32      0.58      0.29     20257\n",
      "weighted avg       0.69      0.49      0.56     20257\n",
      "\n",
      "ROC AUC Score: N/A\n",
      "Confusion Matrix:\n",
      " [[   3    0    0    0]\n",
      " [2489 8358 1955 2387]\n",
      " [ 628 1385  725 1013]\n",
      " [ 220  241   96  757]]\n",
      "========================================\n",
      "Model: Lasso Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.67      0.01         3\n",
      "           1       0.75      0.99      0.85     15189\n",
      "           2       0.00      0.00      0.00      3751\n",
      "           3       0.00      0.00      0.00      1314\n",
      "\n",
      "    accuracy                           0.74     20257\n",
      "   macro avg       0.19      0.41      0.22     20257\n",
      "weighted avg       0.56      0.74      0.64     20257\n",
      "\n",
      "ROC AUC Score: N/A\n",
      "Confusion Matrix:\n",
      " [[    2     1     0     0]\n",
      " [  208 14981     0     0]\n",
      " [   47  3704     0     0]\n",
      " [   12  1302     0     0]]\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import RidgeClassifier, Lasso\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # For Lasso, convert continuous predictions to binary predictions\n",
    "    if isinstance(model, Lasso):\n",
    "        y_pred = (y_pred > 0.5).astype(int)  # Convert continuous output to binary using threshold\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    (\"Ridge Regression\", RidgeClassifier()),\n",
    "    (\"Lasso Regression\", Lasso(max_iter=500))  # Note: Lasso is typically not for classification\n",
    "]\n",
    "\n",
    "# Loop through models and evaluate each\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d34c7-282d-4f39-ba66-8f1a30ce7230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# SVM Classifier with scaling\n",
    "svm_model = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('classifier', SVC(probability=True, random_state=42))  # Set probability=True for ROC AUC score\n",
    "])\n",
    "\n",
    "# Evaluate SVM Classifier\n",
    "evaluate_model(\"Support Vector Machine\", svm_model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a8c60-44f6-4228-be21-08d1646040a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
