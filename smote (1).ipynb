{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb959ecd-2dfe-47b4-84cf-65cdfc2c84f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.7414\n",
      "Weighted Precision: 0.7480\n",
      "Weighted Recall: 0.7414\n",
      "Weighted F1 Score: 0.7443\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1277  196   48]\n",
      " [ 175  175   24]\n",
      " [  38   43   50]]\n",
      "Classification Report (per class metrics):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.84      0.85      1521\n",
      "           2       0.42      0.47      0.44       374\n",
      "           3       0.41      0.38      0.40       131\n",
      "\n",
      "    accuracy                           0.74      2026\n",
      "   macro avg       0.56      0.56      0.56      2026\n",
      "weighted avg       0.75      0.74      0.74      2026\n",
      "\n",
      "--------------------------------------------------\n",
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: Random Forest\n",
      "Accuracy: 0.8159\n",
      "Weighted Precision: 0.7993\n",
      "Weighted Recall: 0.8159\n",
      "Weighted F1 Score: 0.7861\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1487   24   10]\n",
      " [ 237  117   20]\n",
      " [  62   20   49]]\n",
      "Classification Report (per class metrics):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.98      0.90      1521\n",
      "           2       0.73      0.31      0.44       374\n",
      "           3       0.62      0.37      0.47       131\n",
      "\n",
      "    accuracy                           0.82      2026\n",
      "   macro avg       0.73      0.55      0.60      2026\n",
      "weighted avg       0.80      0.82      0.79      2026\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes to reduce memory usage\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'  # Adjust if needed based on your encoded column names\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Please check the column names.\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Optionally downsample the dataset (use a fraction of the data)\n",
    "sample_fraction = 0.1  # Adjust the fraction as necessary to reduce the dataset size\n",
    "data_sampled = data.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "X_sampled = data_sampled.drop([target_column], axis=1)\n",
    "y_sampled = data_sampled[target_column]\n",
    "\n",
    "# Convert the features to a sparse matrix for memory efficiency\n",
    "X_sparse = sparse.csr_matrix(X_sampled)\n",
    "\n",
    "# Train-test split\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(X_sparse, y_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler(with_mean=False)  # with_mean=False for sparse matrices\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    \n",
    "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "    (\"Random Forest\", RandomForestClassifier())\n",
    "]\n",
    "\n",
    "# Function to evaluate models and print performance metrics\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Modified function to evaluate models and print performance metrics for each class\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Multi-class roc_auc_score\n",
    "    if y_proba is not None and len(set(y_test)) > 2:\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "        except ValueError as e:\n",
    "            auc_score = None\n",
    "            print(f\"Warning: {e}\")\n",
    "    elif y_proba is not None:\n",
    "        auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    else:\n",
    "        auc_score = None\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Classification report for per-class metrics\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Print out the metrics\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted Precision: {precision:.4f}\")\n",
    "    print(f\"Weighted Recall: {recall:.4f}\")\n",
    "    print(f\"Weighted F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {auc_score:.4f}\" if auc_score else \"ROC AUC: Not applicable\")\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"Classification Report (per class metrics):\\n\", class_report)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Loop through models and evaluate each\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62da7717-2ace-4a65-88c4-156ca3c2d376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: Bagging Classifier\n",
      "Accuracy: 0.8228\n",
      "Weighted Precision: 0.8047\n",
      "Weighted Recall: 0.8228\n",
      "Weighted F1 Score: 0.8029\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1464   47   10]\n",
      " [ 208  148   18]\n",
      " [  50   26   55]]\n",
      "Classification Report (per class metrics):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.96      0.90      1521\n",
      "           2       0.67      0.40      0.50       374\n",
      "           3       0.66      0.42      0.51       131\n",
      "\n",
      "    accuracy                           0.82      2026\n",
      "   macro avg       0.73      0.59      0.64      2026\n",
      "weighted avg       0.80      0.82      0.80      2026\n",
      "\n",
      "--------------------------------------------------\n",
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: Extra Trees Classifier\n",
      "Accuracy: 0.7922\n",
      "Weighted Precision: 0.7676\n",
      "Weighted Recall: 0.7922\n",
      "Weighted F1 Score: 0.7461\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1494   22    5]\n",
      " [ 287   79    8]\n",
      " [  76   23   32]]\n",
      "Classification Report (per class metrics):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.98      0.88      1521\n",
      "           2       0.64      0.21      0.32       374\n",
      "           3       0.71      0.24      0.36       131\n",
      "\n",
      "    accuracy                           0.79      2026\n",
      "   macro avg       0.72      0.48      0.52      2026\n",
      "weighted avg       0.77      0.79      0.75      2026\n",
      "\n",
      "--------------------------------------------------\n",
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: XGBoost\n",
      "Accuracy: 0.8435\n",
      "Weighted Precision: 0.8315\n",
      "Weighted Recall: 0.8435\n",
      "Weighted F1 Score: 0.8272\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[1478   29   14]\n",
      " [ 188  170   16]\n",
      " [  43   27   61]]\n",
      "Classification Report (per class metrics):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.97      0.92      1521\n",
      "           2       0.75      0.45      0.57       374\n",
      "           3       0.67      0.47      0.55       131\n",
      "\n",
      "    accuracy                           0.84      2026\n",
      "   macro avg       0.76      0.63      0.68      2026\n",
      "weighted avg       0.83      0.84      0.83      2026\n",
      "\n",
      "--------------------------------------------------\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2702\n",
      "[LightGBM] [Info] Number of data points in the train set: 8102, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -8.306719\n",
      "[LightGBM] [Info] Start training from score -0.283494\n",
      "[LightGBM] [Info] Start training from score -1.702775\n",
      "[LightGBM] [Info] Start training from score -2.742199\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Warning: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "Model: LightGBM\n",
      "Accuracy: 0.7517\n",
      "Weighted Precision: 0.7457\n",
      "Weighted Recall: 0.7517\n",
      "Weighted F1 Score: 0.7473\n",
      "ROC AUC: Not applicable\n",
      "Confusion Matrix:\n",
      " [[   0    0    0    0]\n",
      " [   3 1324  133   61]\n",
      " [   1  197  137   39]\n",
      " [   0   43   26   62]]\n",
      "Classification Report (per class metrics):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.85      0.87      0.86      1521\n",
      "           2       0.46      0.37      0.41       374\n",
      "           3       0.38      0.47      0.42       131\n",
      "\n",
      "    accuracy                           0.75      2026\n",
      "   macro avg       0.42      0.43      0.42      2026\n",
      "weighted avg       0.75      0.75      0.75      2026\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, roc_auc_score, confusion_matrix, classification_report)\n",
    "from sklearn.ensemble import (GradientBoostingClassifier, AdaBoostClassifier,\n",
    "                              BaggingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier  # Ensure DecisionTreeClassifier is imported\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.discriminant_analysis import (QuadraticDiscriminantAnalysis,\n",
    "                                            LinearDiscriminantAnalysis)\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes to reduce memory usage\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'  # Adjust if needed based on your encoded column names\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Please check the column names.\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Optionally downsample the dataset (use a fraction of the data)\n",
    "sample_fraction = 0.1  # Adjust the fraction as necessary to reduce the dataset size\n",
    "data_sampled = data.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "X_sampled = data_sampled.drop([target_column], axis=1)\n",
    "y_sampled = data_sampled[target_column]\n",
    "\n",
    "# Convert the features to a sparse matrix for memory efficiency\n",
    "X_sparse = sparse.csr_matrix(X_sampled)\n",
    "\n",
    "# Train-test split\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(X_sparse, y_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler(with_mean=False)  # with_mean=False for sparse matrices\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    (\"Bagging Classifier\", BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50)),  # Updated Bagging Classifier\n",
    "    (\"Extra Trees Classifier\", ExtraTreesClassifier()),  # Extra Trees Classifier\n",
    "    (\"XGBoost\", xgb.XGBClassifier()),  # XGBoost\n",
    "    (\"LightGBM\", lgb.LGBMClassifier()),  # LightGBM\n",
    "]\n",
    "\n",
    "# Function to evaluate models and print performance metrics for each class\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Multi-class roc_auc_score\n",
    "    if y_proba is not None and len(set(y_test)) > 2:\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr')\n",
    "        except ValueError as e:\n",
    "            auc_score = None\n",
    "            print(f\"Warning: {e}\")\n",
    "    elif y_proba is not None:\n",
    "        auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    else:\n",
    "        auc_score = None\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Classification report for per-class metrics\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Print out the metrics\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Weighted Precision: {precision:.4f}\")\n",
    "    print(f\"Weighted Recall: {recall:.4f}\")\n",
    "    print(f\"Weighted F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {auc_score:.4f}\" if auc_score else \"ROC AUC: Not applicable\")\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"Classification Report (per class metrics):\\n\", class_report)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Convert sparse matrices to dense arrays\n",
    "X_train_scaled_dense = X_train_scaled.toarray() if hasattr(X_train_scaled, \"toarray\") else X_train_scaled\n",
    "X_test_scaled_dense = X_test_scaled.toarray() if hasattr(X_test_scaled, \"toarray\") else X_test_scaled\n",
    "\n",
    "# Loop through models and evaluate each\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_scaled_dense, X_test_scaled_dense, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f659ca9b-5a5b-47a4-90ca-0c7298b8d817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CatBoost Classifier\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.97      0.91      1521\n",
      "           2       0.71      0.40      0.51       374\n",
      "           3       0.62      0.40      0.49       131\n",
      "\n",
      "    accuracy                           0.83      2026\n",
      "   macro avg       0.73      0.59      0.63      2026\n",
      "weighted avg       0.81      0.83      0.81      2026\n",
      "\n",
      "Error calculating ROC AUC: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "========================================\n",
      "Model: Nearest Centroid Classifier\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.83      0.50      0.62      1521\n",
      "           2       0.25      0.32      0.28       374\n",
      "           3       0.18      0.57      0.28       131\n",
      "\n",
      "    accuracy                           0.47      2026\n",
      "   macro avg       0.32      0.35      0.29      2026\n",
      "weighted avg       0.68      0.47      0.54      2026\n",
      "\n",
      "ROC AUC Score: N/A\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Histogram-Based Gradient Boosting\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.86      0.96      0.90      1521\n",
      "           2       0.70      0.41      0.52       374\n",
      "           3       0.54      0.44      0.48       131\n",
      "\n",
      "    accuracy                           0.82      2026\n",
      "   macro avg       0.52      0.45      0.48      2026\n",
      "weighted avg       0.81      0.82      0.81      2026\n",
      "\n",
      "Error calculating ROC AUC: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the models you want to evaluate\n",
    "models = [\n",
    "    (\"CatBoost Classifier\", CatBoostClassifier(verbose=0)),  # CatBoost\n",
    "    (\"Nearest Centroid Classifier\", NearestCentroid()),  # Nearest Centroid\n",
    "    (\"Histogram-Based Gradient Boosting\", HistGradientBoostingClassifier())  # Histogram-based GB\n",
    "    \n",
    "]\n",
    "# Function to evaluate the model\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # For multi-class, predict_proba will return probabilities for all classes\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    \n",
    "    # Print classification report (precision, recall, f1 for each class)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Calculate ROC AUC for multi-class\n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Assuming you have your data prepared and scaled\n",
    "# Example of scaling (make sure you do this before fitting the models)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_scaled_dense)\n",
    "X_test_scaled = scaler.transform(X_test_scaled_dense)\n",
    "\n",
    "# Loop through models and evaluate each\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "499c1da4-d060-4638-a28a-c802c221654c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      1.00      0.86      1521\n",
      "           2       0.40      0.01      0.02       374\n",
      "           3       0.25      0.02      0.03       131\n",
      "\n",
      "    accuracy                           0.75      2026\n",
      "   macro avg       0.47      0.34      0.30      2026\n",
      "weighted avg       0.66      0.75      0.65      2026\n",
      "\n",
      "Error calculating ROC AUC: Number of classes in y_true not equal to the number of columns in 'y_score'\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic Regression for classification\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes to reduce memory usage\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'  # Adjust if needed based on your encoded column names\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Please check the column names.\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Optionally downsample the dataset (use a fraction of the data)\n",
    "sample_fraction = 0.1  # Adjust the fraction as necessary to reduce the dataset size\n",
    "data_sampled = data.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "X_sampled = data_sampled.drop([target_column], axis=1)\n",
    "y_sampled = data_sampled[target_column]\n",
    "\n",
    "# Convert the features to a sparse matrix for memory efficiency\n",
    "X_sparse = sparse.csr_matrix(X_sampled)\n",
    "\n",
    "# Train-test split\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(X_sparse, y_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler(with_mean=False)  # with_mean=False for sparse matrices\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression(max_iter=500))  # Logistic Regression for classification\n",
    "]\n",
    "\n",
    "# Function to evaluate models and print performance metrics\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Print the classification report\n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Compute ROC AUC for multi-class\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    if y_proba is not None and len(set(y_test)) > 2:\n",
    "        try:\n",
    "            auc_score = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", auc_score)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: Not applicable\")\n",
    "    \n",
    "    print(\"=\" * 40)\n",
    "\n",
    "# Loop through models and evaluate each\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6fe690-e6b0-4f8d-8603-945fa92e6105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Lasso Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      1.00      0.86      1521\n",
      "           2       0.00      0.00      0.00       374\n",
      "           3       0.00      0.00      0.00       131\n",
      "\n",
      "    accuracy                           0.75      2026\n",
      "   macro avg       0.25      0.33      0.29      2026\n",
      "weighted avg       0.56      0.75      0.64      2026\n",
      "\n",
      "ROC AUC Score: Not applicable\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from scipy import sparse\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes to reduce memory usage\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'  # Adjust if needed based on your encoded column names\n",
    "\n",
    "# Ensure the target column exists\n",
    "if target_column not in data.columns:\n",
    "    raise ValueError(f\"Target column '{target_column}' not found. Please check the column names.\")\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Optionally downsample the dataset (use a fraction of the data)\n",
    "sample_fraction = 0.1  # Adjust the fraction as necessary to reduce the dataset size\n",
    "data_sampled = data.sample(frac=sample_fraction, random_state=42)\n",
    "\n",
    "X_sampled = data_sampled.drop([target_column], axis=1)\n",
    "y_sampled = data_sampled[target_column]\n",
    "\n",
    "# Convert the features to a sparse matrix for memory efficiency\n",
    "X_sparse = sparse.csr_matrix(X_sampled)\n",
    "\n",
    "# Train-test split\n",
    "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(X_sparse, y_sampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler(with_mean=False)  # with_mean=False for sparse matrices\n",
    "X_train_scaled = scaler.fit_transform(X_train_sparse)\n",
    "X_test_scaled = scaler.transform(X_test_sparse)\n",
    "\n",
    "# List of models to evaluate (Lasso Regression in this case)\n",
    "models = [\n",
    "    (\"Lasso Regression\", Lasso(alpha=0.1, max_iter=500))  # Lasso for classification (use thresholding)\n",
    "]\n",
    "\n",
    "# Function to evaluate models and print performance metrics\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Threshold the continuous predictions for binary classification\n",
    "    y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "    # Print the classification report\n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred_binary))\n",
    "\n",
    "    # Compute ROC AUC for binary classification\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]  # For binary classification\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "    else:\n",
    "        print(\"ROC AUC Score: Not applicable\")\n",
    "    \n",
    "    print(\"=\" * 40)\n",
    "\n",
    "# Loop through models and evaluate each\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3544dd67-54e8-4f4b-9fd6-48a496610490",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc3fa15-1fca-4926-bf02-0712ec7ae129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.91      0.86      0.88     15189\n",
      "           2       0.54      0.62      0.58      3751\n",
      "           3       0.53      0.62      0.57      1314\n",
      "\n",
      "    accuracy                           0.80     20257\n",
      "   macro avg       0.49      0.52      0.51     20257\n",
      "weighted avg       0.81      0.80      0.81     20257\n",
      "\n",
      "ROC AUC Score: 0.7086803483257109\n",
      "Confusion Matrix:\n",
      " [[    0     2     1     0]\n",
      " [    6 13101  1676   406]\n",
      " [    0  1131  2307   313]\n",
      " [    1   218   286   809]]\n",
      "========================================\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.91      0.95      0.93     15189\n",
      "           2       0.76      0.59      0.66      3751\n",
      "           3       0.67      0.75      0.71      1314\n",
      "\n",
      "    accuracy                           0.87     20257\n",
      "   macro avg       0.58      0.57      0.57     20257\n",
      "weighted avg       0.86      0.87      0.86     20257\n",
      "\n",
      "ROC AUC Score: 0.9130046879668248\n",
      "Confusion Matrix:\n",
      " [[    0     2     0     1]\n",
      " [    5 14388   560   236]\n",
      " [    1  1292  2201   257]\n",
      " [    0   175   150   989]]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# First set of 5 models\n",
    "models_1 = [\n",
    "   \n",
    "    (\"Decision Tree\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', DecisionTreeClassifier(class_weight='balanced'))])),\n",
    "    \n",
    "    (\"Random Forest\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', RandomForestClassifier(random_state=42))])),\n",
    "    \n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "# Loop through models and evaluate\n",
    "for name, model in models_1:\n",
    "    evaluate_model(name, model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3be79a06-6d45-4a07-a6ef-fc1f270314e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Bagging Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.91      0.93      0.92     15189\n",
      "           2       0.72      0.61      0.66      3751\n",
      "           3       0.61      0.71      0.66      1314\n",
      "\n",
      "    accuracy                           0.86     20257\n",
      "   macro avg       0.56      0.56      0.56     20257\n",
      "weighted avg       0.86      0.86      0.86     20257\n",
      "\n",
      "ROC AUC Score: 0.8659973669425541\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [    5 14189   691   304]\n",
      " [    1  1182  2271   297]\n",
      " [    1   184   191   938]]\n",
      "========================================\n",
      "Model: Extra Trees Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.89      0.95      0.92     15189\n",
      "           2       0.72      0.51      0.59      3751\n",
      "           3       0.68      0.72      0.70      1314\n",
      "\n",
      "    accuracy                           0.85     20257\n",
      "   macro avg       0.57      0.54      0.55     20257\n",
      "weighted avg       0.84      0.85      0.84     20257\n",
      "\n",
      "ROC AUC Score: 0.9390365310714168\n",
      "Confusion Matrix:\n",
      " [[    0     2     1     0]\n",
      " [    5 14378   602   204]\n",
      " [    1  1607  1903   240]\n",
      " [    0   221   151   942]]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Second set of 5 models\n",
    "models_2 = [\n",
    "   \n",
    "    \n",
    "    (\"Bagging Classifier\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', BaggingClassifier(n_estimators=50, random_state=42))])),\n",
    "    \n",
    "    (\"Extra Trees Classifier\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', ExtraTreesClassifier(random_state=42))]))\n",
    "]\n",
    "\n",
    "# Loop through models and evaluate\n",
    "for name, model in models_2:\n",
    "    evaluate_model(name, model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825448ce-86be-443a-89ee-3ed832f6da73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Histogram-Based Gradient Boosting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.90      0.93      0.91     15189\n",
      "           2       0.72      0.49      0.59      3751\n",
      "           3       0.55      0.78      0.65      1314\n",
      "\n",
      "    accuracy                           0.84     20257\n",
      "   macro avg       0.54      0.55      0.54     20257\n",
      "weighted avg       0.84      0.84      0.83     20257\n",
      "\n",
      "ROC AUC Score: 0.8473610782478216\n",
      "Confusion Matrix:\n",
      " [[    0     3     0     0]\n",
      " [   16 14133   637   403]\n",
      " [    6  1455  1851   439]\n",
      " [    1   195    87  1031]]\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:01:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.90      0.95      0.92     15189\n",
      "           2       0.77      0.54      0.63      3751\n",
      "           3       0.61      0.79      0.69      1314\n",
      "\n",
      "    accuracy                           0.86     20257\n",
      "   macro avg       0.57      0.57      0.56     20257\n",
      "weighted avg       0.86      0.86      0.85     20257\n",
      "\n",
      "ROC AUC Score: 0.9335244816578858\n",
      "Confusion Matrix:\n",
      " [[    0     1     1     1]\n",
      " [   15 14358   520   296]\n",
      " [    4  1360  2026   361]\n",
      " [    1   191    87  1035]]\n",
      "========================================\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3067\n",
      "[LightGBM] [Info] Number of data points in the train set: 243764, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "Model: LightGBM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.89      0.92      0.91     15189\n",
      "           2       0.69      0.47      0.56      3751\n",
      "           3       0.54      0.80      0.64      1314\n",
      "\n",
      "    accuracy                           0.83     20257\n",
      "   macro avg       0.53      0.55      0.53     20257\n",
      "weighted avg       0.83      0.83      0.83     20257\n",
      "\n",
      "ROC AUC Score: 0.918870443159423\n",
      "Confusion Matrix:\n",
      " [[    0     1     1     1]\n",
      " [   16 14036   722   415]\n",
      " [    2  1518  1754   477]\n",
      " [    1   188    77  1048]]\n",
      "========================================\n",
      "Model: CatBoost Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.90      0.94      0.92     15189\n",
      "           2       0.74      0.54      0.62      3751\n",
      "           3       0.60      0.77      0.68      1314\n",
      "\n",
      "    accuracy                           0.85     20257\n",
      "   macro avg       0.56      0.56      0.56     20257\n",
      "weighted avg       0.85      0.85      0.85     20257\n",
      "\n",
      "ROC AUC Score: 0.9356760093371789\n",
      "Confusion Matrix:\n",
      " [[    0     1     1     1]\n",
      " [   14 14291   590   294]\n",
      " [    3  1360  2013   375]\n",
      " [    1   196   102  1015]]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Model list with only the specified classifiers\n",
    "models = [\n",
    "   \n",
    "    (\"Histogram-Based Gradient Boosting\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', HistGradientBoostingClassifier(random_state=42))])),\n",
    "    \n",
    "    (\"XGBoost\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))])),\n",
    "    \n",
    "    (\"LightGBM\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', lgb.LGBMClassifier(random_state=42))])),\n",
    "    \n",
    "    (\"CatBoost Classifier\", \n",
    "     Pipeline([('scaler', scaler), \n",
    "               ('classifier', CatBoostClassifier(silent=True))]))\n",
    "]\n",
    "\n",
    "# Loop through models and evaluate\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfb8dd6c-fed6-4df4-9fcc-f3b7574535b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Nearest Centroid Classifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      1.00      0.00         3\n",
      "           1       0.84      0.51      0.63     15189\n",
      "           2       0.24      0.30      0.27      3751\n",
      "           3       0.17      0.52      0.26      1314\n",
      "\n",
      "    accuracy                           0.47     20257\n",
      "   macro avg       0.31      0.58      0.29     20257\n",
      "weighted avg       0.69      0.47      0.54     20257\n",
      "\n",
      "ROC AUC Score: N/A\n",
      "Confusion Matrix:\n",
      " [[   3    0    0    0]\n",
      " [1856 7710 3331 2292]\n",
      " [ 492 1200 1110  949]\n",
      " [ 209  243  183  679]]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr')\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# Nearest Centroid Classifier with scaling\n",
    "nearest_centroid_model = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('classifier', NearestCentroid())\n",
    "])\n",
    "\n",
    "# Evaluate Nearest Centroid Classifier\n",
    "evaluate_model(\"Nearest Centroid Classifier\", nearest_centroid_model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d93a95fe-9513-41e0-bc1c-a1202398e604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Lasso Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.67      0.01         3\n",
      "           1       0.75      0.99      0.85     15189\n",
      "           2       0.00      0.00      0.00      3751\n",
      "           3       0.00      0.00      0.00      1314\n",
      "\n",
      "    accuracy                           0.74     20257\n",
      "   macro avg       0.19      0.41      0.22     20257\n",
      "weighted avg       0.56      0.74      0.64     20257\n",
      "\n",
      "ROC AUC Score: N/A\n",
      "Confusion Matrix:\n",
      " [[    2     1     0     0]\n",
      " [  208 14981     0     0]\n",
      " [   47  3704     0     0]\n",
      " [   12  1302     0     0]]\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\saini\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import RidgeClassifier, Lasso\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('updated_food_inspection_cleaned.csv')\n",
    "\n",
    "# Convert categorical columns to category codes\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Define the target column\n",
    "target_column = 'Risk'\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop([target_column], axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # For Lasso, convert continuous predictions to binary predictions\n",
    "    if isinstance(model, Lasso):\n",
    "        y_pred = (y_pred > 0.5).astype(int)  # Convert continuous output to binary using threshold\n",
    "    \n",
    "    # Predict probabilities for models that support it\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    print(f\"Model: {name}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        try:\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            print(\"ROC AUC Score:\", roc_auc)\n",
    "        except ValueError as e:\n",
    "            print(\"Error calculating ROC AUC:\", e)\n",
    "    else:\n",
    "        print(\"ROC AUC Score: N/A\")\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "# List of models to evaluate\n",
    "models = [\n",
    "    \n",
    "    (\"Lasso Regression\", Lasso(max_iter=500))  # Note: Lasso is typically not for classification\n",
    "]\n",
    "\n",
    "# Loop through models and evaluate each\n",
    "for name, model in models:\n",
    "    evaluate_model(name, model, X_train_resampled, X_test, y_train_resampled, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97776da2-912d-4753-9e82-7be07d8538c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
